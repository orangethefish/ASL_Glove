{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiChanel- Deep Convolutional Neural Network (MC-DCNN):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try the 2 stage MC-DCNN (http://staff.ustc.edu.cn/~cheneh/paper_pdf/2014/Yi-Zheng-WAIM2014.pdf) architecture.  \n",
    "#### Here features are first learned idependently on each channel with a cascade of 1D convolutions and maxpooling, then the learned features are concatenated and fed into a MLP. The MLP is in charge of learning the correlations between channels and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louis/Documents/Theano/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.signal import butter, lfilter, freqz, spectrogram\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.options.mode.chained_assignment = None\n",
    "from random import random\n",
    "# import scipy\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import fft\n",
    "from numpy.random import randint\n",
    "# Lasagne (& friends) imports\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from nolearn.lasagne import BatchIterator, NeuralNet\n",
    "from lasagne.objectives import aggregate, binary_crossentropy\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer,InverseLayer, DropoutLayer, DenseLayer,Conv1DLayer,MaxPool1DLayer,\\\n",
    "Upscale1DLayer, ReshapeLayer\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from theano.tensor.nnet import sigmoid\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Silence some warnings from lasagne\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*topo.*')\n",
    "warnings.filterwarnings('ignore', module='.*lasagne.init.*')\n",
    "warnings.filterwarnings('ignore', module='.*nolearn.lasagne.*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############Data loading and processing pipeline###########\n",
    "# A couple of classes let us deal with parameters, and preprocessing of biometrig data (ppg + accelerometer)\n",
    "# we do some preprocessing, incuding replacing missing values,\n",
    "#turning date/hour into floats, scaling, and low pass filter\n",
    "# The time series are sliced into windows of length FREQ_WINDOW\n",
    "class Param(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.N_USERS = 10\n",
    "        self.N_CHANNELS = 22\n",
    "        self.TEST_TRAIN_SPLIT = 0.80 # fraction of data for train/test\n",
    "        # low pass filter requirements.\n",
    "        self.ORDER = 1\n",
    "        self.FS = 1.0 # approx sample rate, Hz\n",
    "        self.CUTOFF = 0.00046# desired cutoff frequency,Hz(~30 minute periods)\n",
    "        self.SUBSAMPLE = 40\n",
    "        # spectrogram requirement:\n",
    "        self.FREQ_WINDOW = 800 # size of the sliding window\n",
    "        self.STEP = self.FREQ_WINDOW-400\n",
    "        \n",
    "        \n",
    "class BioDataset(object):\n",
    "    \n",
    "    def __init__(self,filename,Param):\n",
    "        \n",
    "        self.filename = filename\n",
    "        self.p = Param # pass data and preprossing parameters\n",
    "        self.scaler_1 = None # initialize pre-pross feature scaler\n",
    "        self.scaler_2 = None # initialize post-pross feature scaler\n",
    "    \n",
    "    def butter_lowpass(self):\n",
    "        \"\"\" construct butter low pass filter \"\"\"\n",
    "        nyq = 0.5 * self.p.FS\n",
    "        normal_cutoff = self.p.CUTOFF / nyq\n",
    "        b, a = butter(self.p.ORDER, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "    def butter_lowpass_filter(self,data):\n",
    "        \"\"\" apply butter low pass filter to data \"\"\"\n",
    "        b, a = self.butter_lowpass()\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\" load and clean data \"\"\"\n",
    "        # Read data\n",
    "        X = pd.read_csv(self.filename,parse_dates = ['_datetime','_calendar_date'])\n",
    "        # Clean up missing values \n",
    "        X = X.dropna(axis ='index', thresh=0)\n",
    "        X = X.fillna(axis = 'index',method = 'bfill')\n",
    "        X = X.fillna(axis = 'index',method = 'ffill')\n",
    "\n",
    "        return  X\n",
    "\n",
    "    def split_train_test(self,X):\n",
    "        \"\"\" split data into train/test group chronologically \"\"\"\n",
    "        # reasign parameters locally for readibility\n",
    "        N_USERS = self.p.N_USERS\n",
    "        TEST_TRAIN_SPLIT = self.p.TEST_TRAIN_SPLIT\n",
    "        FREQ_WINDOW = self.p.FREQ_WINDOW\n",
    "        \n",
    "        X_sort = X.sort_values(by=['_datetime'])\n",
    "        X_sort['_calendar_date'] = pd.DatetimeIndex(X_sort['_calendar_date']).weekday\n",
    "        X_sort['_datetime'] = pd.DatetimeIndex(X_sort['_datetime']).hour\n",
    "    \n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        for n in range(N_USERS):\n",
    "            # split data into 75-25% train/test, chronologically, for each user\n",
    "            X_user = X_sort[X_sort['_user_id']==n]\n",
    "            split_indice = int(np.floor(X_user.shape[0]*TEST_TRAIN_SPLIT))\n",
    "            X_train += [X_user[:split_indice]]\n",
    "            X_test += [X_user[split_indice:]]\n",
    "            \n",
    "        X_train = pd.concat(X_train)\n",
    "        X_train.drop('_cap_seq', axis=1, inplace=True)\n",
    "\n",
    "        X_test = pd.concat(X_test)\n",
    "        X_test.drop('_cap_seq', axis=1, inplace=True)\n",
    "        \n",
    "        return X_train,X_test\n",
    "\n",
    "    def preprocess_data(self,X):\n",
    "        \"\"\" preprocess (scaling + low pass filter + spectrogram) training data \"\"\"\n",
    "        # reasign parameters locally for readibility\n",
    "        N_USERS = self.p.N_USERS\n",
    "        TEST_TRAIN_SPLIT = self.p.TEST_TRAIN_SPLIT\n",
    "        FREQ_WINDOW = self.p.FREQ_WINDOW\n",
    "        N_CHANNELS = self.p.N_CHANNELS\n",
    "        STEP = self.p.STEP\n",
    "        \n",
    "        # Separate data into users \n",
    "        X_user = [X[X['_user_id']==i] for i in range(N_USERS) if i != 8]\n",
    "\n",
    "        # Remove user id information\n",
    "        for n,us in enumerate(X_user):\n",
    "            X_user[n].drop('_user_id', axis=1, inplace=True)\n",
    "\n",
    "        # Construct a feature scaler (scaling of test data is done with mean and std from train data)\n",
    "        if self.scaler_1 is None:\n",
    "            self.scaler_1 = StandardScaler().fit(np.asarray(pd.concat(X_user)).astype(float))\n",
    "\n",
    "        X_windowed = np.array([]).reshape((0,FREQ_WINDOW,N_CHANNELS+2))\n",
    "        y_windowed = []\n",
    "        X_n = []\n",
    "        X_prepro = []\n",
    "        X_prepro_scaled = []\n",
    "        # Features extraction\n",
    "        for n in range(N_USERS-1):\n",
    "            # scale the features:\n",
    "            X_prep_normal = self.scaler_1.transform((np.asarray(X_user[n])).astype(float))\n",
    "            X_prep_low = np.zeros((np.shape(X_prep_normal)[0],N_CHANNELS))\n",
    "            \n",
    "            for col in range(N_CHANNELS):\n",
    "                z0 = X_prep_normal[:,col+2][0]\n",
    "                # apply a low pass filter:\n",
    "                X_prep_low[:,col] = z0 + self.butter_lowpass_filter(X_prep_normal[:,col+2]-z0)\n",
    "            \n",
    "            X_prepro += [np.hstack([X_prep_normal[:,:2],X_prep_low])]\n",
    "            \n",
    "        if self.scaler_2 is None:\n",
    "            self.scaler_2 = StandardScaler().fit(np.concatenate(X_prepro).astype(float))\n",
    "\n",
    "        \n",
    "        for n in range(N_USERS-1):\n",
    "            print \"preprocessing user %d...\"%n\n",
    "            X_prepro_scaled = self.scaler_2.transform(X_prepro[n])\n",
    "            for k in range(0,X_prepro_scaled.shape[0]-FREQ_WINDOW,STEP):\n",
    "               \n",
    "                X_windowed = np.vstack([X_windowed,X_prepro_scaled[k:k+FREQ_WINDOW\\\n",
    "                                                                   ,...].reshape((1,FREQ_WINDOW,N_CHANNELS+2))])\n",
    "                \n",
    "                y_windowed += [n]\n",
    "            print \"done\"\n",
    "                \n",
    "        return np.swapaxes(X_windowed,1,2).astype(\"float32\"), np.array([y_windowed]).astype(\"int32\").reshape(-1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing user 0...\n",
      "done\n",
      "preprocessing user 1...\n",
      "done\n",
      "preprocessing user 2...\n",
      "done\n",
      "preprocessing user 3...\n",
      "done\n",
      "preprocessing user 4...\n",
      "done\n",
      "preprocessing user 5...\n",
      "done\n",
      "preprocessing user 6...\n",
      "done\n",
      "preprocessing user 7...\n",
      "done\n",
      "preprocessing user 8...\n",
      "done\n",
      "preprocessing user 0...\n",
      "done\n",
      "preprocessing user 1...\n",
      "done\n",
      "preprocessing user 2...\n",
      "done\n",
      "preprocessing user 3...\n",
      "done\n",
      "preprocessing user 4...\n",
      "done\n",
      "preprocessing user 5...\n",
      "done\n",
      "preprocessing user 6...\n",
      "done\n",
      "preprocessing user 7...\n",
      "done\n",
      "preprocessing user 8...\n",
      "done\n",
      "(420, 24, 800) (95, 24, 800)\n",
      "-0.000799445 0.986007\n",
      "0.00186059 1.01973\n"
     ]
    }
   ],
   "source": [
    "parameters = Param()\n",
    "ds = BioDataset('biodb.csv',parameters)\n",
    "# load data:\n",
    "X_raw = ds.load_data()\n",
    "X_train_raw,X_test_raw = ds.split_train_test(X_raw)\n",
    "\n",
    "X_train,y_train_total = ds.preprocess_data(X_train_raw)\n",
    "y_train = label_binarize(y_train_total,classes=range(parameters.N_USERS-1)).astype(\"int32\")\n",
    "# Prepocess test data (here the scaling is done using mean and std from training data):\n",
    "X_test,y_test_total = ds.preprocess_data(X_test_raw)\n",
    "y_test = label_binarize(y_test_total,classes=range(parameters.N_USERS-1)).astype(\"int32\")\n",
    "\n",
    "print X_train.shape, X_test.shape\n",
    "print X_train.mean(), X_train.std()\n",
    "print X_test.mean(), X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from batchNormalization import BatchNormLayer\n",
    "\n",
    "def batch_norm(layer, **kwargs):\n",
    "    nonlinearity = getattr(layer, 'nonlinearity', None)\n",
    "    if nonlinearity is not None:\n",
    "        layer.nonlinearity = lasagne.nonlinearities.identity\n",
    "    if hasattr(layer, 'b') and layer.b is not None:\n",
    "        del layer.params[layer.b]\n",
    "        layer.b = None\n",
    "    layer = BatchNormLayer(layer, **kwargs)\n",
    "    if nonlinearity is not None:\n",
    "        from lasagne.layers import NonlinearityLayer\n",
    "        layer = NonlinearityLayer(layer, nonlinearity)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def iterator(X, batchsize):\n",
    "    indices = np.arange(len(X))\n",
    "    for i in range(0, len(X) - batchsize + 1, batchsize):\n",
    "        sli = indices[i:i+batchsize]\n",
    "        yield X[sli]\n",
    "\n",
    "def save_params(model, fn):\n",
    "    with open(fn, 'w') as wr:\n",
    "        pickle.dump(lasagne.layers.get_all_param_values(model), wr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC DCNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = None\n",
    "\n",
    "def build_MC_DCNN(input_var = [None]*(parameters.N_CHANNELS+2)):\n",
    "    \n",
    "    conv_num_filters1 = 4\n",
    "    conv_num_filters2 = 4\n",
    "    filter_size1 = 5\n",
    "    filter_size2 = 5\n",
    "    pool_size = 4\n",
    "    pad_in = 'valid'\n",
    "    pad_out = 'full'\n",
    "    dense_units = 32\n",
    "    ########################\n",
    "    # Here we build a dictionnary to construct independent layers for each channel:\n",
    "    network = {} \n",
    "    for i in range(parameters.N_CHANNELS+2):\n",
    "        \n",
    "        network[i] = InputLayer(shape=(batch_size,1,parameters.FREQ_WINDOW),input_var=input_var[i],name=\"input_layer_1\")  \n",
    "        \n",
    "        network[i] = batch_norm(Conv1DLayer(\n",
    "                network[i], num_filters=conv_num_filters1, filter_size=filter_size1,\n",
    "                nonlinearity=lasagne.nonlinearities.tanh,\n",
    "                W=lasagne.init.GlorotUniform(),pad = pad_in,name=\"conv1_1\"))\n",
    "\n",
    "        network[i] = MaxPool1DLayer(network[i], pool_size=pool_size,name=\"pool1_1\")\n",
    "\n",
    "        network[i] = batch_norm(Conv1DLayer(\n",
    "                network[i], num_filters=conv_num_filters2, filter_size=filter_size2,\n",
    "                nonlinearity=lasagne.nonlinearities.tanh,\n",
    "                W=lasagne.init.GlorotUniform(),pad = pad_in,name=\"conv2_1\"))\n",
    "\n",
    "        network[i] = MaxPool1DLayer(network[i], pool_size=pool_size,name=\"pool2_1\")\n",
    "\n",
    "        network[i] = ReshapeLayer(network[i], shape = ([0],-1), name = \"reshape_1\")\n",
    "        \n",
    "    \n",
    "    #######################\n",
    "    # Now we concatenate the output from each channel layer, and build a MLP:\n",
    "    \n",
    "    network2 = lasagne.layers.ConcatLayer(network.values(),axis = 1, name = \"concat\")\n",
    "    \n",
    "    \n",
    "    network2 = batch_norm(lasagne.layers.DenseLayer(network2, num_units=dense_units, \\\n",
    "                                  W = lasagne.init.GlorotUniform(),name = \"dense1\"))\n",
    "    \n",
    "    network2 = batch_norm(lasagne.layers.DenseLayer(network2, num_units=parameters.N_USERS-1, \\\n",
    "                                  W = lasagne.init.GlorotUniform(), \\\n",
    "                                  nonlinearity=lasagne.nonlinearities.softmax,name = \"output\"))\n",
    "    \n",
    "    return network2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('input_layer_1', (None, 1, 800))\n",
      "('conv1_1', (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "(None, (None, 4, 796))\n",
      "('pool1_1', (None, 4, 199))\n",
      "('conv2_1', (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "(None, (None, 4, 195))\n",
      "('pool2_1', (None, 4, 48))\n",
      "('reshape_1', (None, 192))\n",
      "('concat', (None, 4608))\n",
      "('dense1', (None, 32))\n",
      "(None, (None, 32))\n",
      "(None, (None, 32))\n",
      "('output', (None, 9))\n",
      "(None, (None, 9))\n",
      "(None, (None, 9))\n",
      "number of parameters is 151076\n"
     ]
    }
   ],
   "source": [
    "## The target values (correct classes) are stored a one hot matrix, of size Training_samples x classes\n",
    "target_values = T.imatrix('target_output')\n",
    "\n",
    "# we then build a dictionary of input variables (one per channel)\n",
    "inps = {}\n",
    "for i in range(parameters.N_CHANNELS+2):\n",
    "    inps[i] = T.tensor3()\n",
    "\n",
    "# Let's build the MC_DCNN, and check the architecture by printing out the layer sizes and names:\n",
    "network = build_MC_DCNN(inps.values())\n",
    "\n",
    "laylist = lasagne.layers.get_all_layers(network)\n",
    "    \n",
    "for l in laylist:\n",
    "    print(l.name, lasagne.layers.get_output_shape(l))\n",
    "\n",
    "num_params = lasagne.layers.count_params(network)\n",
    "\n",
    "print(\"number of parameters is {}\".format(num_params))\n",
    "\n",
    "# lasagne.layers.get_output produces an expression for the output of the net:\n",
    "network_output = lasagne.layers.get_output(network)\n",
    "\n",
    "# Our cost will be categorical cross-entropie\n",
    "cost = lasagne.objectives.categorical_crossentropy(network_output, target_values)\n",
    "cost = cost.mean()\n",
    "\n",
    "# Retrieve all parameters from the network\n",
    "all_params = lasagne.layers.get_all_params(network ,trainable = True)\n",
    "# Compute adam updates for training\n",
    "updates = lasagne.updates.adam(cost, all_params)\n",
    "# Theano functions for training and computing cost. \n",
    "train = theano.function(inps.values()+[target_values],cost, updates=updates)\n",
    "compute_cost = theano.function(inps.values()+[target_values], cost)\n",
    "\n",
    "# Theano functions for forward pass:\n",
    "predicted_values = lasagne.layers.get_output(network, deterministic=True)\n",
    "predict = theano.function(inps.values(),[predicted_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEKCAYAAAAYd05sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131e6bf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 205/400 [16:03<14:49,  4.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ff034ce99a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0margList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louis/Documents/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/louis/Documents/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs: \n",
    "num_epochs = 400\n",
    "error_train = []\n",
    "error_val = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    batch_siz = 42\n",
    "    for batch in iterate_minibatches(X_train, y_train, batch_siz, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        #Here we splits the input into individual channels:\n",
    "        inputs2 = [inputs[:,i,:].reshape(-1,1,parameters.FREQ_WINDOW) for i in range(parameters.N_CHANNELS+2)]\n",
    "        argList = inputs2+[targets]\n",
    "        \n",
    "        train_err += train(*argList)\n",
    "        train_batches += 1\n",
    "        \n",
    "    #And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 95, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        inputs2 = [inputs[:,i,:].reshape(-1,1,parameters.FREQ_WINDOW) for i in range(parameters.N_CHANNELS+2)]\n",
    "        argList = inputs2+[targets]\n",
    "        \n",
    "        val_err += compute_cost(*argList)\n",
    "        val_batches += 1\n",
    "\n",
    "    error_train += [train_err / train_batches]\n",
    "    error_val += [val_err / val_batches]\n",
    "    \n",
    "    \n",
    "    # Each epoch, we do some predictions on the test data and compute the F1 score:\n",
    "    inputs_pred = [X_test[:,i,:].reshape(-1,1,parameters.FREQ_WINDOW) for i in range(parameters.N_CHANNELS+2)]\n",
    "    \n",
    "    y_pred = [y.argmax() for y in predict(*inputs_pred)[0]]\n",
    "    y_true = [y.argmax() for y in y_test]\n",
    "\n",
    "    # Let's plot the training/testing error\n",
    "    pl.plot(error_train)\n",
    "    pl.plot(error_val)\n",
    "    pl.title(\"F1 score {}\".format(f1_score(y_true, y_pred)))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
